{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import scipy.io as sio\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "num_workers = 2\n",
    "sets_sizes = {'train' : 0.7,\n",
    "              'test' : 0.3}\n",
    "batch_size = 64\n",
    "edge_size = 28\n",
    "input_size = edge_size * edge_size\n",
    "output_size = 10\n",
    "epochs_num = 50\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# download and load the dataset mnist784 with 70000 images\n",
    "dataset = torch.utils.data.ConcatDataset([datasets.MNIST(root='./data', train=False, download=True, transform=transform),\n",
    "                                          datasets.MNIST(root='./data', train=True, download=True, transform=transform)])\n",
    "\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting the train data to train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and validation sets using torch.utils.data.random_split\n",
    "train_size = int(sets_sizes['train'] * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating dataloader for train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GpuDataLoader:\n",
    "    def __init__(self, dl):\n",
    "        self.dl = dl\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return map(lambda batch: (batch[0].to(device), batch[1].to(device)), self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataloader for train, validation and test\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    train_loader = GpuDataLoader(train_loader)\n",
    "    test_loader = GpuDataLoader(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualizing several images from the train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch of images shape:  torch.Size([64, 1, 28, 28])\n",
      "batch of labels shape:  torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get a single batch\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "print(\"batch of images shape: \", images.shape)\n",
    "print(\"batch of labels shape: \", labels.shape)\n",
    "\n",
    "# show batch 6 first images\n",
    "fig, axs = plt.subplots(2, 3, constrained_layout=True)\n",
    "for idx, ax in enumerate(axs.ravel()):\n",
    "    ax.imshow(images[idx].cpu().numpy().transpose((1, 2,0)))\n",
    "    ax.set_title(str(labels[idx].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully connected neural network\n",
    "class FC_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size=10):\n",
    "        super(FC_Model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "\n",
    "        # fully connected layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Linear(input_size, hidden_sizes[0]))\n",
    "        self.layers.append(nn.Sigmoid())\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "            self.layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
    "            self.layers.append(nn.Sigmoid())\n",
    "        self.layers.append(nn.Linear(hidden_sizes[-1], output_size))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training and score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_onehot(y, num_labels):\n",
    "    \n",
    "    ary = np.zeros((y.shape[0], num_labels))\n",
    "    for i, val in enumerate(y):\n",
    "        ary[i, val] = 1\n",
    "\n",
    "    return ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(model, set='train'):\n",
    "  if set == 'train':\n",
    "      loader = train_loader\n",
    "  elif set == 'val':\n",
    "      loader = val_loader\n",
    "  elif set == 'test':\n",
    "      loader = test_loader\n",
    "  else:\n",
    "      raise ValueError('set must be one of train, val, test')\n",
    "\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  with torch.no_grad():\n",
    "    for images, labels in loader:\n",
    "\n",
    "      outputs = model(images)\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      total += labels.shape[0]\n",
    "      correct += (predicted == labels).sum().item()\n",
    "  return correct / total\n",
    "\n",
    "def calc_loss(model, set='train'):\n",
    "  if set == 'train':\n",
    "    loader = train_loader\n",
    "  elif set == 'val':\n",
    "    loader = val_loader\n",
    "  elif set == 'test':\n",
    "    loader = test_loader\n",
    "  else:\n",
    "    raise ValueError('set must be one of train, val, test')\n",
    "\n",
    "  loss = 0\n",
    "  with torch.no_grad():\n",
    "    for images, labels in loader:\n",
    "      outputs = model(images)\n",
    "      loss += F.mse_loss(outputs, torch.Tensor(int_to_onehot(labels, output_size)))\n",
    "  return loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs_num=30, lr=0.001, log_dir=None):\n",
    "  writer = SummaryWriter(log_dir=log_dir)\n",
    "  criterion = nn.MSELoss()\n",
    "  optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "  for epoch in tqdm(range(epochs_num)):\n",
    "    for idx, batch in enumerate(train_loader):\n",
    "      X, y = batch\n",
    "\n",
    "      output = model(X)\n",
    "      loss = criterion(output, torch.Tensor(int_to_onehot(y, output_size)))\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    # log the losses and accuracy after every epoch\n",
    "    writer.add_scalar('Loss/train', calc_loss(model, set='train'), epoch)\n",
    "    writer.add_scalar('Accuracy/train', calc_acc(model, set='train'), epoch)\n",
    "    writer.flush()\n",
    "\n",
    "    # save model checkpoints after every 5 epochs\n",
    "    if epoch % 5 == 0:\n",
    "          torch.save(model.state_dict(), os.path.join(log_dir, 'model_epoch_{}.pt'.format(epoch)))\n",
    "\n",
    "  writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [21:41<00:00, 26.04s/it]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/fc_[50, 50].pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nirba\\Nir Barel\\BGU\\semester 6\\ML\\A3\\ML-Assignment3\\Task1\\2_layers_torch.ipynb Cell 20\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nirba/Nir%20Barel/BGU/semester%206/ML/A3/ML-Assignment3/Task1/2_layers_torch.ipynb#ch0000021?line=3'>4</a>\u001b[0m fc_model \u001b[39m=\u001b[39m FC_Model(input_size, hidden_sizes, output_size)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nirba/Nir%20Barel/BGU/semester%206/ML/A3/ML-Assignment3/Task1/2_layers_torch.ipynb#ch0000021?line=4'>5</a>\u001b[0m train_model(fc_model, epochs_num\u001b[39m=\u001b[39mepochs_num, log_dir\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./runs/fc/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(hidden_sizes))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nirba/Nir%20Barel/BGU/semester%206/ML/A3/ML-Assignment3/Task1/2_layers_torch.ipynb#ch0000021?line=5'>6</a>\u001b[0m \u001b[48;5;17mtorch\u001b[39m.\u001b[39;49m\u001b[48;5;17msave\u001b[48;5;17m(\u001b[48;5;17mfc_model\u001b[39m.\u001b[39;49m\u001b[48;5;17mstate_dict\u001b[48;5;17m(\u001b[48;5;17m)\u001b[48;5;17m,\u001b[48;5;17m \u001b[39m'\u001b[39;49m\u001b[39m./models/fc_\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[48;5;17m \u001b[39m+\u001b[39;49m\u001b[48;5;17m \u001b[39mstr\u001b[39;49m\u001b[48;5;17m(\u001b[48;5;17mhidden_sizes\u001b[48;5;17m)\u001b[48;5;17m \u001b[39m+\u001b[39;49m\u001b[48;5;17m \u001b[39m'\u001b[39;49m\u001b[39m.pt\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[48;5;17m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\serialization.py\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[39m\"\"\"save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True)\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \n\u001b[0;32m    342\u001b[0m \u001b[39mSaves an object to a disk file.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[39m    >>> torch.save(x, buffer)\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    374\u001b[0m _check_dill_version(pickle_module)\n\u001b[1;32m--> 376\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[48;5;17m_open_file_like\u001b[48;5;17m(\u001b[48;5;17mf\u001b[48;5;17m,\u001b[48;5;17m \u001b[39m'\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[48;5;17m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m    377\u001b[0m     \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m    378\u001b[0m         \u001b[39mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\serialization.py\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 230\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[48;5;17m_open_file\u001b[48;5;17m(\u001b[48;5;17mname_or_buffer\u001b[48;5;17m,\u001b[48;5;17m \u001b[48;5;17mmode\u001b[48;5;17m)\n\u001b[0;32m    231\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\serialization.py\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[1;32m--> 211\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m\u001b[48;5;17m(\u001b[48;5;17mname\u001b[48;5;17m,\u001b[48;5;17m \u001b[48;5;17mmode\u001b[48;5;17m))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/fc_[50, 50].pt'"
     ]
    }
   ],
   "source": [
    "# if model not exist, training it\n",
    "hidden_sizes = [50,50]\n",
    "if not os.path.exists('./models/fc_' + str(hidden_sizes) + '.pt'):\n",
    "    fc_model = FC_Model(input_size, hidden_sizes, output_size).to(device)\n",
    "    train_model(fc_model, epochs_num=epochs_num, log_dir='./runs/fc/' + str(hidden_sizes))\n",
    "    torch.save(fc_model.state_dict(), './models/fc_' + str(hidden_sizes) + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print test accuracy of the model\n",
    "print('Test accuracy: ', calc_acc(fc_model, set='test'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e77538e53907e2d67847cce25fbeb05bb5a5b783e193f715ae63ebfcddd60c29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
