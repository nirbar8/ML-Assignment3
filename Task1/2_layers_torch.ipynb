{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import scipy.io as sio\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import copy\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "num_workers = 2\n",
    "sets_sizes = {'train' : 0.7,\n",
    "              'test' : 0.3}\n",
    "batch_size = 64\n",
    "edge_size = 28\n",
    "input_size = edge_size * edge_size\n",
    "output_size = 10\n",
    "epochs_num = 40\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# download and load the dataset mnist784 with 70000 images\n",
    "dataset = torch.utils.data.ConcatDataset([datasets.MNIST(root='./data', train=False, download=True, transform=transform),\n",
    "                                          datasets.MNIST(root='./data', train=True, download=True, transform=transform)])\n",
    "\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting the train data to train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and validation sets using torch.utils.data.random_split\n",
    "train_size = int(sets_sizes['train'] * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating dataloader for train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GpuDataLoader:\n",
    "    def __init__(self, dl):\n",
    "        self.dl = dl\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return map(lambda batch: (batch[0].to(device), batch[1].to(device)), self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataloader for train, validation and test\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    train_loader = GpuDataLoader(train_loader)\n",
    "    test_loader = GpuDataLoader(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualizing several images from the train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch of images shape:  torch.Size([64, 1, 28, 28])\n",
      "batch of labels shape:  torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get a single batch\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "print(\"batch of images shape: \", images.shape)\n",
    "print(\"batch of labels shape: \", labels.shape)\n",
    "\n",
    "# show batch 6 first images\n",
    "fig, axs = plt.subplots(2, 3, constrained_layout=True)\n",
    "for idx, ax in enumerate(axs.ravel()):\n",
    "    ax.imshow(images[idx].cpu().numpy().transpose((1, 2,0)))\n",
    "    ax.set_title(str(labels[idx].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully connected neural network\n",
    "class FC_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size=10):\n",
    "        super(FC_Model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "\n",
    "        # fully connected layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Linear(input_size, hidden_sizes[0]))\n",
    "        self.layers.append(nn.Sigmoid())\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "            self.layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
    "            self.layers.append(nn.Sigmoid())\n",
    "        self.layers.append(nn.Linear(hidden_sizes[-1], output_size))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training and score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(model, set='train'):\n",
    "  if set == 'train':\n",
    "      loader = train_loader\n",
    "  elif set == 'val':\n",
    "      loader = val_loader\n",
    "  elif set == 'test':\n",
    "      loader = test_loader\n",
    "  else:\n",
    "      raise ValueError('set must be one of train, val, test')\n",
    "\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  with torch.no_grad():\n",
    "    for images, labels in loader:\n",
    "\n",
    "      outputs = model(images)\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      total += labels.shape[0]\n",
    "      correct += (predicted == labels).sum().item()\n",
    "  return correct / total\n",
    "\n",
    "def calc_loss(model, set='train'):\n",
    "  if set == 'train':\n",
    "    loader = train_loader\n",
    "  elif set == 'val':\n",
    "    loader = val_loader\n",
    "  elif set == 'test':\n",
    "    loader = test_loader\n",
    "  else:\n",
    "    raise ValueError('set must be one of train, val, test')\n",
    "\n",
    "  loss = 0\n",
    "  with torch.no_grad():\n",
    "    for images, labels in loader:\n",
    "      outputs = model(images)\n",
    "      loss += F.mse_loss(outputs, torch.Tensor(int_to_onehot(labels, output_size)))\n",
    "  return loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs_num=30, lr=0.001, log_dir=None):\n",
    "  writer = SummaryWriter(log_dir=log_dir)\n",
    "  criterion = nn.MSELoss()\n",
    "  optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "  for epoch in tqdm(range(epochs_num)):\n",
    "    for idx, batch in enumerate(train_loader):\n",
    "      X, y = batch\n",
    "\n",
    "      output = model(X)\n",
    "      loss = criterion(output, torch.Tensor(int_to_onehot(y, output_size)))\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    # log the losses and accuracy after every epoch\n",
    "    writer.add_scalar('Loss/train', calc_loss(model, set='train'), epoch)\n",
    "    writer.add_scalar('Accuracy/train', calc_acc(model, set='train'), epoch)\n",
    "    writer.flush()\n",
    "\n",
    "    # save model checkpoints after every 5 epochs\n",
    "    if epoch % 5 == 0:\n",
    "          torch.save(model.state_dict(), os.path.join(log_dir, 'model_epoch_{}.pt'.format(epoch)))\n",
    "\n",
    "  writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_onehot(y, num_labels):\n",
    "    \n",
    "    ary = np.zeros((y.shape[0], num_labels))\n",
    "    for i, val in enumerate(y):\n",
    "        ary[i, val] = 1\n",
    "\n",
    "    return ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [15:11<00:00, 22.79s/it]\n"
     ]
    }
   ],
   "source": [
    "# if model not exist, training it\n",
    "hidden_sizes = [50,50]\n",
    "model_path = './model_torch_fc_2_layers.pt'\n",
    "fc_model = FC_Model(input_size, hidden_sizes, output_size).to(device)\n",
    "if not os.path.exists(model_path):\n",
    "    train_model(fc_model, epochs_num=epochs_num, log_dir='./runs/fc_torch/' + str(hidden_sizes))\n",
    "    torch.save(fc_model.state_dict(), model_path)\n",
    "else:\n",
    "    fc_model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert test_dataset to tensor X_test and y_test\n",
    "X_test = torch.Tensor([]).view(-1, input_size)\n",
    "y_test = torch.Tensor([])\n",
    "for images, labels in test_loader:\n",
    "    images = images.view(-1, input_size)\n",
    "    X_test = torch.cat((X_test, images.cpu()))\n",
    "    y_test = torch.cat((y_test, labels.cpu()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model acc on test set:  96.638 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model acc on test set: \", round(calc_acc(fc_model, set='test') * 100, 3), '%') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model macro auc on test set: 99.742 %\n"
     ]
    }
   ],
   "source": [
    "probs = fc_model(X_test).detach().numpy()\n",
    "probs = np.array([x / np.sum(x) for x in probs])\n",
    "test_macro_auc = roc_auc_score(y_test, probs, average='macro', multi_class='ovr')\n",
    "print(f'Model macro auc on test set: {round(test_macro_auc * 100, 3)}', '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e77538e53907e2d67847cce25fbeb05bb5a5b783e193f715ae63ebfcddd60c29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
